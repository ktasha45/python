{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tqdm\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTransform():\n",
    "  def __init__(self, mean=0.5, std=0.5):\n",
    "    self.data_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "\n",
    "  def __call__(self, img):\n",
    "    return self.data_transform(img)\n",
    "\n",
    "class make_dataset(data.Dataset):\n",
    "  def __init__(self, idx_list, file, transform, mode):\n",
    "    self.file = file\n",
    "    self.idx_list = idx_list\n",
    "    self.mode = mode\n",
    "    self.transform = transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.idx_list)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    img = self.transform(self.file[index, 1:33].reshape(8, 4))\n",
    "    # if self.mode == 'train':\n",
    "    #   label = self.file[index, 33].astype('int64')\n",
    "    #   return img, label\n",
    "    # else:\n",
    "    #   return img\n",
    "    img2 = torch.zeros((1,8,4))\n",
    "    for i in range(4):\n",
    "      img2[0, :, i] = img[0, :, 3-i]\n",
    "\n",
    "    if self.mode == 'train':\n",
    "      label = self.file[index, 33].astype('int64')\n",
    "      return torch.cat([img, img2], dim=0).type('torch.FloatTensor'), label\n",
    "    else:\n",
    "      return torch.cat([img, img2], dim=0).type('torch.FloatTensor')\n",
    "\n",
    "def make_dataloader(batch_size=32, valid_size=0.2):\n",
    "    traindata = pd.read_csv('../data/train.csv').to_numpy()\n",
    "    testdata = pd.read_csv('../data/test.csv').to_numpy()\n",
    "\n",
    "    num_train = len(traindata)\n",
    "    indices = list(range(num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    split = np.int32(np.floor(valid_size * num_train))\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "    test_idx = list(range(len(testdata)))\n",
    "\n",
    "    train_set = make_dataset(train_idx, traindata, ImageTransform(), 'train')\n",
    "    valid_set = make_dataset(valid_idx, traindata, ImageTransform(), 'train')\n",
    "    test_set = make_dataset(test_idx, testdata, ImageTransform(), 'test')\n",
    "\n",
    "    train_loader = data.DataLoader(train_set, batch_size=batch_size)\n",
    "    valid_loader = data.DataLoader(valid_set, batch_size=batch_size)\n",
    "    test_loader = data.DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, test_loader, valid_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(2,128,kernel_size=2,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(128,128,kernel_size=2,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Conv2d(128,128,kernel_size=2,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(128,256,kernel_size=2,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Conv2d(256,256,kernel_size=2,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(256,512,kernel_size=2,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Conv2d(512,512,kernel_size=2,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(512,1024,kernel_size=2,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(256, 4)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, target = batch\n",
    "        pred = self(x)\n",
    "        loss = self.loss_fn(pred, target)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "   \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, target = batch\n",
    "        pred = self(x)\n",
    "        loss = self.loss_fn(pred, target)\n",
    "        acc = torchmetrics.functional.accuracy(pred, target)\n",
    "        metrics = {'val_acc': acc, 'val_loss': loss}\n",
    "        self.log_dict(metrics)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(torch.__version__)\n",
    "    print(print(torch.cuda.get_device_name(0)))\n",
    "\n",
    "    batch_size = 128\n",
    "    train_loader, test_loader, valid_loader = make_dataloader(batch_size)\n",
    "\n",
    "    print(train_loader.dataset.__len__())\n",
    "    print(valid_loader.dataset.__len__())\n",
    "\n",
    "    print(train_loader.dataset.__getitem__(0)[0].shape)\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 24))\n",
    "    for i, (imgs, labels) in enumerate(train_loader):\n",
    "        print(imgs.shape)\n",
    "        break\n",
    "        for j in range(9):\n",
    "            ax = fig.add_subplot(3, 3, j + 1)\n",
    "            ax.set_xlabel(labels[j].numpy())\n",
    "            plt.imshow(imgs[j][0])\n",
    "        break\n",
    "\n",
    "    model = network()\n",
    "\n",
    "    print(summary(model, input_size=(batch_size, 2, 8, 4)))\n",
    "\n",
    "    callbacks = [EarlyStopping(monitor=\"val_loss\", patience=15, verbose=False)]\n",
    "    trainer = pl.Trainer(max_epochs=300, gpus=1, callbacks=callbacks)\n",
    "    trainer.fit(model, train_loader, valid_loader)\n",
    "    \n",
    "\n",
    "    sample_submission = pd.read_csv('../data/sample_submission.csv')\n",
    "    batch_index = 0\n",
    "    for i, data in enumerate(test_loader):\n",
    "        outputs = model.forward(data)\n",
    "        batch_index = i * batch_size\n",
    "        max_vals, max_indices = torch.max(outputs, 1)\n",
    "        sample_submission.iloc[batch_index:batch_index + batch_size, 1:] = max_indices.long().cpu().numpy()[:,np.newaxis]\n",
    "    sample_submission.to_csv('version26.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n",
      "NVIDIA GeForce MX250\n",
      "None\n",
      "1868\n",
      "467\n",
      "torch.Size([2, 8, 4])\n",
      "torch.Size([128, 2, 8, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "network                                  --                        --\n",
      "├─CrossEntropyLoss: 1-1                  --                        --\n",
      "├─Sequential: 1-2                        [128, 4]                  --\n",
      "│    └─Conv2d: 2-1                       [128, 128, 9, 5]          1,152\n",
      "│    └─BatchNorm2d: 2-2                  [128, 128, 9, 5]          256\n",
      "│    └─ELU: 2-3                          [128, 128, 9, 5]          --\n",
      "│    └─Dropout: 2-4                      [128, 128, 9, 5]          --\n",
      "│    └─Conv2d: 2-5                       [128, 128, 10, 6]         65,664\n",
      "│    └─BatchNorm2d: 2-6                  [128, 128, 10, 6]         256\n",
      "│    └─ELU: 2-7                          [128, 128, 10, 6]         --\n",
      "│    └─Dropout: 2-8                      [128, 128, 10, 6]         --\n",
      "│    └─Conv2d: 2-9                       [128, 128, 11, 7]         65,664\n",
      "│    └─BatchNorm2d: 2-10                 [128, 128, 11, 7]         256\n",
      "│    └─ELU: 2-11                         [128, 128, 11, 7]         --\n",
      "│    └─Dropout: 2-12                     [128, 128, 11, 7]         --\n",
      "│    └─Conv2d: 2-13                      [128, 256, 12, 8]         131,328\n",
      "│    └─BatchNorm2d: 2-14                 [128, 256, 12, 8]         512\n",
      "│    └─ELU: 2-15                         [128, 256, 12, 8]         --\n",
      "│    └─Dropout: 2-16                     [128, 256, 12, 8]         --\n",
      "│    └─Conv2d: 2-17                      [128, 256, 13, 9]         262,400\n",
      "│    └─BatchNorm2d: 2-18                 [128, 256, 13, 9]         512\n",
      "│    └─ELU: 2-19                         [128, 256, 13, 9]         --\n",
      "│    └─Dropout: 2-20                     [128, 256, 13, 9]         --\n",
      "│    └─Conv2d: 2-21                      [128, 512, 14, 10]        524,800\n",
      "│    └─BatchNorm2d: 2-22                 [128, 512, 14, 10]        1,024\n",
      "│    └─ELU: 2-23                         [128, 512, 14, 10]        --\n",
      "│    └─Dropout: 2-24                     [128, 512, 14, 10]        --\n",
      "│    └─Conv2d: 2-25                      [128, 512, 15, 11]        1,049,088\n",
      "│    └─BatchNorm2d: 2-26                 [128, 512, 15, 11]        1,024\n",
      "│    └─ELU: 2-27                         [128, 512, 15, 11]        --\n",
      "│    └─Dropout: 2-28                     [128, 512, 15, 11]        --\n",
      "│    └─Conv2d: 2-29                      [128, 1024, 16, 12]       2,098,176\n",
      "│    └─BatchNorm2d: 2-30                 [128, 1024, 16, 12]       2,048\n",
      "│    └─ELU: 2-31                         [128, 1024, 16, 12]       --\n",
      "│    └─Dropout: 2-32                     [128, 1024, 16, 12]       --\n",
      "│    └─AdaptiveAvgPool2d: 2-33           [128, 1024, 1, 1]         --\n",
      "│    └─Flatten: 2-34                     [128, 1024]               --\n",
      "│    └─Linear: 2-35                      [128, 256]                262,400\n",
      "│    └─BatchNorm1d: 2-36                 [128, 256]                512\n",
      "│    └─ELU: 2-37                         [128, 256]                --\n",
      "│    └─Dropout: 2-38                     [128, 256]                --\n",
      "│    └─Linear: 2-39                      [128, 4]                  1,028\n",
      "==========================================================================================\n",
      "Total params: 4,468,100\n",
      "Trainable params: 4,468,100\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 89.86\n",
      "==========================================================================================\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 882.38\n",
      "Params size (MB): 17.87\n",
      "Estimated Total Size (MB): 900.29\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | loss_fn | CrossEntropyLoss | 0     \n",
      "1 | net     | Sequential       | 4.5 M \n",
      "---------------------------------------------\n",
      "4.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.5 M     Total params\n",
      "17.872    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\torch\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\torch\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\torch\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:432: UserWarning: The number of training samples (15) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50:  68%|██████▊   | 13/19 [00:14<00:06,  1.13s/it, loss=0.4, v_num=26]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\torch\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\godspell\\python\\notebook\\dacon\\gestureclassify\\attempt4\\attemp4.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/godspell/python/notebook/dacon/gestureclassify/attempt4/attemp4.ipynb#ch0000004?line=0'>1</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/godspell/python/notebook/dacon/gestureclassify/attempt4/attemp4.ipynb#ch0000004?line=1'>2</a>\u001b[0m     main()\n",
      "\u001b[1;32mc:\\godspell\\python\\notebook\\dacon\\gestureclassify\\attempt4\\attemp4.ipynb Cell 4'\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/godspell/python/notebook/dacon/gestureclassify/attempt4/attemp4.ipynb#ch0000003?line=32'>33</a>\u001b[0m batch_index \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/godspell/python/notebook/dacon/gestureclassify/attempt4/attemp4.ipynb#ch0000003?line=33'>34</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(test_loader):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/godspell/python/notebook/dacon/gestureclassify/attempt4/attemp4.ipynb#ch0000003?line=34'>35</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/godspell/python/notebook/dacon/gestureclassify/attempt4/attemp4.ipynb#ch0000003?line=35'>36</a>\u001b[0m     batch_index \u001b[39m=\u001b[39m i \u001b[39m*\u001b[39m batch_size\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/godspell/python/notebook/dacon/gestureclassify/attempt4/attemp4.ipynb#ch0000003?line=36'>37</a>\u001b[0m     max_vals, max_indices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(outputs, \u001b[39m1\u001b[39m)\n",
      "\u001b[1;32mc:\\godspell\\python\\notebook\\dacon\\gestureclassify\\attempt4\\attemp4.ipynb Cell 3'\u001b[0m in \u001b[0;36mnetwork.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/godspell/python/notebook/dacon/gestureclassify/attempt4/attemp4.ipynb#ch0000002?line=51'>52</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/godspell/python/notebook/dacon/gestureclassify/attempt4/attemp4.ipynb#ch0000002?line=52'>53</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnet(x)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/torch/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/torch/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/torch/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/torch/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/ProgramData/Anaconda3/envs/torch/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/torch/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/torch/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/torch/lib/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/torch/lib/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> <a href='file:///c%3A/ProgramData/Anaconda3/envs/torch/lib/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/torch/lib/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/torch/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/torch/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/torch/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/torch/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/ProgramData/Anaconda3/envs/torch/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/torch/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Anaconda3/envs/torch/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\conv.py:447\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/torch/lib/site-packages/torch/nn/modules/conv.py?line=445'>446</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> <a href='file:///c%3A/ProgramData/Anaconda3/envs/torch/lib/site-packages/torch/nn/modules/conv.py?line=446'>447</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\conv.py:443\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/torch/lib/site-packages/torch/nn/modules/conv.py?line=438'>439</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/torch/lib/site-packages/torch/nn/modules/conv.py?line=439'>440</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/torch/lib/site-packages/torch/nn/modules/conv.py?line=440'>441</a>\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/torch/lib/site-packages/torch/nn/modules/conv.py?line=441'>442</a>\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> <a href='file:///c%3A/ProgramData/Anaconda3/envs/torch/lib/site-packages/torch/nn/modules/conv.py?line=442'>443</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    <a href='file:///c%3A/ProgramData/Anaconda3/envs/torch/lib/site-packages/torch/nn/modules/conv.py?line=443'>444</a>\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x1728 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50:  68%|██████▊   | 13/19 [00:31<00:14,  2.43s/it, loss=0.4, v_num=26]"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = pd.read_csv('../data/train.csv').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 4)\n",
      "(8, 4)\n",
      "(8, 4)\n",
      "(8, 4)\n",
      "(8, 4)\n",
      "(8, 4)\n",
      "(8, 4)\n",
      "(8, 4)\n",
      "(8, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x1728 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12, 24))\n",
    "for j in range(9):\n",
    "    img = traindata[j, 1:33].reshape((8, 4))\n",
    "    label = traindata[j, 33]\n",
    "    print(img.shape)\n",
    "    ax = fig.add_subplot(3, 3, j + 1)\n",
    "    ax.set_xlabel(label)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -6.1494632   -0.92971357   9.05836761  -7.01785369]\n",
      " [ -2.95847138   0.179233    -0.95659101  -0.97240086]\n",
      " [  5.95621278   4.14563573  25.01764496  -4.06125365]\n",
      " [  0.99663162  -3.83734549 -13.95699405  -2.04295728]\n",
      " [  2.13020964  -1.95766247  -1.14993047   6.08202762]\n",
      " [  0.8786122    5.09310164  -6.06664753  -7.02643577]\n",
      " [ -6.00628223  -6.00583611   7.04308355  21.88465021]\n",
      " [ -3.06415192  -5.2475518   -6.02610749 -11.9908216 ]]\n",
      "[[ -2.23883638  -1.0035114    5.09807901 -10.88035741]\n",
      " [ -0.80456235  -2.99212304  26.97272407  -8.90086087]\n",
      " [ -5.96829834  -4.06013351   2.95284269  -5.04635318]\n",
      " [  1.08381865   3.97837803 -25.07254153  -2.04160214]\n",
      " [  2.91226875  -3.99803505   6.06969811   4.96618658]\n",
      " [  1.99405085  -1.13205948  14.90620531  -1.9967135 ]\n",
      " [ -7.9338059   -3.13677267   8.77421138  10.94475869]\n",
      " [  9.85818622  -0.96924102  -3.93555279 -15.89242069]]\n",
      "[[ 19.08793392  -2.09251433   0.94674955 -21.83178755]\n",
      " [  9.11923488  17.85358741 -21.0699539  -15.93321192]\n",
      " [ -9.01603893  -5.97519444 -23.21840847  -9.00062969]\n",
      " [  9.11595714  12.09731775 -10.95436685  -3.93071416]\n",
      " [-19.06959447  -6.11894035  -5.00134583  -9.10537122]\n",
      " [ -9.89488499  10.10761419   4.94857003  -6.88968512]\n",
      " [ 54.05232952  -6.10923796  12.15459503   6.09598917]\n",
      " [-40.19508817  -3.95812387  -8.07953684  -5.16008972]]\n",
      "[[ -2.21162857  -1.93090391  21.8884055   -3.06755958]\n",
      " [ -0.24063398   2.98505616 -29.07336927   0.20077359]\n",
      " [ -1.04374212   2.09984519 -15.12377438  -0.06986694]\n",
      " [ -0.11424706  -1.89610891   5.12719415  -2.8774228 ]\n",
      " [  2.97004432  -1.09970222   3.11676673   8.12420895]\n",
      " [ -0.91741775  -1.02719871  14.04829826  -2.12617029]\n",
      " [ -1.03552568   2.17876927  10.03272304  -1.01089672]\n",
      " [ -3.91284793  -2.98033797 -12.98359737  -3.00107677]]\n",
      "[[  3.95385219   2.96489227 -36.04480185   0.89983806]\n",
      " [ 26.93021023  11.00440889 -21.96242285 -11.95018858]\n",
      " [-20.93378518  -4.00050639  16.01044186   5.96121916]\n",
      " [  9.90711511  -0.06775401  -9.97072842   0.86849896]\n",
      " [  1.89223329  -3.16169842  -9.22599017   3.95395597]\n",
      " [-17.95965184  -3.11549103  -6.05167431  -2.05176055]\n",
      " [ 10.91756708   1.90533525 -13.00470678  17.1695521 ]\n",
      " [  2.10519444   3.96798565  11.86165709 -27.08884605]]\n",
      "[[ 2.82001086e+01  4.03807210e+00 -2.40278809e+01  3.02889750e+00]\n",
      " [-3.49922778e+01  1.85647779e+00  3.70731306e+01  2.69732767e+01]\n",
      " [ 8.93495252e+00 -1.26001982e-02  9.10464651e+00 -2.80091220e+01]\n",
      " [-1.78777298e+01  3.86983926e+00 -2.02588080e+00  4.11164264e+00]\n",
      " [-3.90849630e+00 -5.81057550e+00  1.58187168e+01 -1.99296231e+00]\n",
      " [ 2.20814897e+01 -1.26096287e+00 -1.19914853e+01  4.75326075e+00]\n",
      " [-1.89117805e+01 -2.09401914e+00 -3.49942789e+01 -9.88606655e+00]\n",
      " [ 4.14264571e+00  2.03661181e+00  4.40659324e+01  1.30972622e+01]]\n",
      "[[ -0.13976329  -2.95041369   2.95375532  -7.89571066]\n",
      " [ -0.76788707  -1.94478115   1.05257829  11.09061493]\n",
      " [ -0.08703333  -1.00155364  13.85103478  -8.93088527]\n",
      " [ -0.93206181  -2.94562915  -6.94024008  -1.09314089]\n",
      " [  2.90244639   0.93125964   1.93664712   6.98976723]\n",
      " [  2.71952755  -1.16782976   1.96530964  -2.05808407]\n",
      " [ -2.86425427   1.97767317 -16.89756144  -7.98009488]\n",
      " [ -5.03070641  -5.96204503  14.04404255  10.83130228]]\n",
      "[[ -8.02107116   2.06106293  11.93665213  21.06762082]\n",
      " [  1.92631763  -5.89388338   5.9754641  -11.07830696]\n",
      " [  8.08454006  -1.14583106  -4.98348328  26.11678667]\n",
      " [ 20.96535195  -3.80003329  -7.1595536   -2.9186402 ]\n",
      " [ 11.77208669  -1.97397058 -23.92976583  -4.90632741]\n",
      " [ -4.04854136  -0.9458566   17.88260821 -14.08177753]\n",
      " [ -1.12334809  -1.06655299  -2.03290467   1.89640765]\n",
      " [-28.0958096    2.94160568   4.96668121   3.96925673]]\n",
      "[[  5.96940045   0.91145792  -6.23825944   5.08999546]\n",
      " [  3.11489884  -2.05151374   5.08237398   0.10619877]\n",
      " [ -0.0163215   -0.15584704  10.03995339 -10.04776084]\n",
      " [ -4.93069689  -2.02548072  -2.8885807    1.89182891]\n",
      " [  0.96444165   2.87996324  -8.21056154  -2.03437198]\n",
      " [  0.8060773   -1.15481575  -5.93174378  -5.86400118]\n",
      " [ -2.14575834  -1.0327911    8.05957475   2.98737978]\n",
      " [ -4.13492205  -1.97961264   5.06969304   1.89852255]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x1728 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12, 24))\n",
    "for j in range(9):\n",
    "    img = traindata[j, 1:33].reshape((8, 4))\n",
    "    img\n",
    "    for n in range(4*2-1):\n",
    "        for m in range(8*2-1):\n",
    "            \n",
    "    label = traindata[j, 33]\n",
    "    print(img)\n",
    "    # ax = fig.add_subplot(3, 3, j + 1)\n",
    "    # ax.set_xlabel(label)\n",
    "    # plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b69a98d3df882577ba469635c4ab08c5ae67eaedfd3a57f311f98966a6edb2d0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
